trainer:
  _target_: trainer.trajectory_wise_trainer.OnPolicyTrainer

epochs: 25000
batch_size: 300

fwd_loss: tb

exploratory: true
exploration_factor: 0.2
exploration_wd: true

optimizer:
  lr_policy: 1e-3
  lr_flow: 1e-1
  lr_back: 1e-3
  weight_decay: 1e-7
  use_weight_decay: false
